{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2f78d023",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "\n",
    "from matplotlib import pylab as plt\n",
    "from keras.models import Sequential\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.layers.convolutional import Conv1D, MaxPooling1D\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.layers import Dense,LSTM, BatchNormalization, Dropout, Bidirectional, Flatten, LeakyReLU, Conv3D, MaxPooling3D\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "path = os.getcwd() + '/'\n",
    "path_out = 'RESULTADOS_REDES/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3496df9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nc4(datos_datos, name):\n",
    "\n",
    "    from datetime import datetime, timedelta\n",
    "    from netCDF4 import Dataset,num2date,date2num\n",
    "        \n",
    "    a = test_data_tem.strftime[0].values\n",
    "    b = test_data_tem.strftime[len(test_data_tem.strftime)-1].values\n",
    "\n",
    "    nyears = len(test_data_tem.strftime);\n",
    "    unout = 'days since ' + str(pd.to_datetime(a).year) + '-' + str(pd.to_datetime(a).month) + '-' + str(pd.to_datetime(a).day)\n",
    "\n",
    "    nx, ny = (len(test_data_tem.latitude), len(test_data_tem.longitude))\n",
    "\n",
    "    lat = test_data_tem.latitude.values\n",
    "    lon = test_data_tem.longitude.values\n",
    "\n",
    "    dataout = datos_datos\n",
    "        \n",
    "    datesout = np.arange(datetime(int(pd.to_datetime(a).year),int(pd.to_datetime(a).month),int(pd.to_datetime(a).day)),\n",
    "                        datetime(int((pd.to_datetime(b) + timedelta(days=1)).year),int((pd.to_datetime(b) + timedelta(days=1)).month),int((pd.to_datetime(b) + timedelta(days=1)).day)),\n",
    "                        timedelta(days = 1)).astype(datetime)\n",
    "        \n",
    "    ncout = Dataset(path + path_out + name + '.nc','w','NETCDF3')\n",
    "    ncout.createDimension('longitude',ny)\n",
    "    ncout.createDimension('latitude',nx)\n",
    "    ncout.createDimension('time',nyears)\n",
    "    lonvar = ncout.createVariable('longitude','float32',('longitude'));lonvar[:] = lon\n",
    "    latvar = ncout.createVariable('latitude','float32',('latitude'));latvar[:] = lat\n",
    "    timevar = ncout.createVariable('time','float64',('time'));timevar.setncattr('units',unout);timevar[:]=date2num(datesout,unout)\n",
    "    myvar = ncout.createVariable(name,'float32',('time','latitude','longitude'));myvar.setncattr('units','');myvar[:] = dataout\n",
    "    ncout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1de5beb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#modis      = pd.read_csv('DATA_SEMILLERO/INCENDIOS_ZONA.csv')\n",
    "nc_org     = xr.open_dataset('DATA_DAY/2m_temperature.nc')-273.15\n",
    "nc_tem_no     = xr.open_dataset('DATA_DAY/t2m_mod.nc')-273.15\n",
    "nc_tem     = xr.open_dataset('DATA_TEM_MOD/t2m_mod.nc')-273.15\n",
    "nc_rad     = xr.open_dataset('DATA_DAY/surface_solar_radiation_downwars.nc')\n",
    "nc_soiltem = xr.open_dataset('DATA_DAY/soil_temperature_level_1.nc')-273.15\n",
    "nc_pre     = xr.open_dataset('DATA_DAY/total_precipitation.nc')*1000\n",
    "nc_dew     = xr.open_dataset('DATA_DAY/2m_dewpoint_temperature.nc')-273.15\n",
    "nc_uwind   = xr.open_dataset('DATA_DAY/10m_u_component_of_wind.nc')\n",
    "nc_vwind   = xr.open_dataset('DATA_DAY/10m_v_component_of_wind.nc')\n",
    "nc_leafhigh= xr.open_dataset('DATA_DAY/leaf_area_index_high_vegetation.nc')\n",
    "nc_leaflow = xr.open_dataset('DATA_DAY/leaf_area_index_low_vegetation.nc')\n",
    "nc_skin    = xr.open_dataset('DATA_DAY/skin_reservoir_content.nc')*1000\n",
    "nc_vol     = xr.open_dataset('DATA_DAY/volumetric_soil_water_layer_1.nc')\n",
    "nc_eva     = xr.open_dataset('DATA_DAY/evaporation.nc')*(-1000)\n",
    "\n",
    "nc_BUI  = xr.open_dataset('../../FWI/RESULTADOS_FWI10_NC/BUI.nc')\n",
    "nc_DC   = xr.open_dataset('../../FWI/RESULTADOS_FWI10_NC/DC.nc')\n",
    "nc_DMC  = xr.open_dataset('../../FWI/RESULTADOS_FWI10_NC/DMC.nc')\n",
    "nc_DSR  = xr.open_dataset('../../FWI/RESULTADOS_FWI10_NC/DSR.nc')\n",
    "nc_FFMC = xr.open_dataset('../../FWI/RESULTADOS_FWI10_NC/FFMC.nc')\n",
    "nc_FWI  = xr.open_dataset('../../FWI/RESULTADOS_FWI10_NC/FWI.nc')\n",
    "nc_ISI  = xr.open_dataset('../../FWI/RESULTADOS_FWI10_NC/ISI.nc')\n",
    "nc_M    = xr.open_dataset('../../FWI/RESULTADOS_FWI10_NC/M.nc')\n",
    "nc_WIND = xr.open_dataset('../../FWI/RESULTADOS_FWI10_NC/WIND.nc')\n",
    "nc_RH   = xr.open_dataset('../../FWI/RESULTADOS_FWI10_NC/RH.nc')\n",
    "\n",
    "nc_org = nc_org.rename({'t2m': 't2m_org'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1c0e1907",
   "metadata": {},
   "outputs": [],
   "source": [
    "tem      = nc_tem.t2m.assign_coords(strftime = nc_tem.t2m.strftime.values.astype('datetime64[ns]'))  #DESACTIVAR con datos modificados en tiempo o long\n",
    "pre      = nc_pre.tp.assign_coords(strftime = nc_pre.tp.strftime.values.astype('datetime64[ns]'))\n",
    "rad      = nc_rad.ssrd.assign_coords(strftime = nc_rad.ssrd.strftime.values.astype('datetime64[ns]'))\n",
    "soiltem  = nc_soiltem.stl1.assign_coords(strftime = nc_soiltem.stl1.strftime.values.astype('datetime64[ns]'))     \n",
    "dew      = nc_dew.d2m.assign_coords(strftime = nc_dew.d2m.strftime.values.astype('datetime64[ns]'))    \n",
    "uwind    = nc_uwind.u10.assign_coords(strftime = nc_uwind.u10.strftime.values.astype('datetime64[ns]'))   \n",
    "vwind    = nc_vwind.v10.assign_coords(strftime = nc_vwind.v10.strftime.values.astype('datetime64[ns]'))  \n",
    "leafhigh = nc_leafhigh.lai_hv.assign_coords(strftime = nc_leafhigh.lai_hv.strftime.values.astype('datetime64[ns]'))\n",
    "leaflow  = nc_leaflow.lai_lv.assign_coords(strftime = nc_leaflow.lai_lv.strftime.values.astype('datetime64[ns]'))\n",
    "skin     = nc_skin.src.assign_coords(strftime = nc_skin.src.strftime.values.astype('datetime64[ns]'))\n",
    "vol      = nc_vol.swvl1.assign_coords(strftime = nc_vol.swvl1.strftime.values.astype('datetime64[ns]'))\n",
    "eva      = nc_eva.e.assign_coords(strftime = nc_eva.e.strftime.values.astype('datetime64[ns]'))\n",
    "\n",
    "nc_BUI  = nc_BUI.BUI.rename({'time':'strftime'}) \n",
    "nc_DC   = nc_DC.DC.rename({'time':'strftime'}) \n",
    "nc_DMC  = nc_DMC.DCM.rename({'time':'strftime'})\n",
    "nc_DSR  = nc_DSR.DSR.rename({'time':'strftime'})\n",
    "nc_FFMC = nc_FFMC.FFMC.rename({'time':'strftime'})\n",
    "nc_FWI  = nc_FWI.FWI.rename({'time':'strftime'})\n",
    "nc_ISI  = nc_ISI.ISI.rename({'time':'strftime'})\n",
    "nc_M    = nc_M.M.rename({'time':'strftime'})\n",
    "nc_WIND = nc_WIND.WIND.rename({'time':'strftime'})\n",
    "nc_RH = nc_RH.RH.rename({'time':'strftime'})\n",
    "\n",
    "BUI  = nc_BUI.assign_coords(strftime = nc_BUI.strftime.values.astype('datetime64[ns]'))  \n",
    "DC   = nc_DC.assign_coords(strftime = nc_DC.strftime.values.astype('datetime64[ns]'))  \n",
    "DMC  = nc_DMC.assign_coords(strftime = nc_DMC.strftime.values.astype('datetime64[ns]'))  \n",
    "DSR  = nc_DSR.assign_coords(strftime = nc_DSR.strftime.values.astype('datetime64[ns]'))  \n",
    "FFMC = nc_FFMC.assign_coords(strftime = nc_FFMC.strftime.values.astype('datetime64[ns]')) \n",
    "FWI  = nc_FWI.assign_coords(strftime = nc_FWI.strftime.values.astype('datetime64[ns]')) \n",
    "ISI  = nc_ISI.assign_coords(strftime = nc_ISI.strftime.values.astype('datetime64[ns]'))  \n",
    "M    = nc_M.assign_coords(strftime = nc_M.strftime.values.astype('datetime64[ns]')) \n",
    "WIND = nc_WIND.assign_coords(strftime = nc_WIND.strftime.values.astype('datetime64[ns]'))\n",
    "RH = nc_RH.assign_coords(strftime = nc_RH.strftime.values.astype('datetime64[ns]'))\n",
    "\n",
    "max_tem = np.max(tem.values)\n",
    "min_tem = np.min(tem.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "24f3cfd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def div(data_var):\n",
    "    max_var = np.max(data_var.values)\n",
    "    min_var = np.min(data_var.values)\n",
    "    result_data_var = (data_var-min_var)/(max_var-min_var)\n",
    "    result_data_var = np.round(result_data_var,4)\n",
    "    return result_data_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8dfd04b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre      = div(pre)\n",
    "eva      = div(eva)\n",
    "rad      = div(rad)\n",
    "soiltem  = div(soiltem)\n",
    "leafhigh = div(leafhigh)\n",
    "skin     = div(skin)\n",
    "vol      = div(vol)\n",
    "tem      = div(tem)\n",
    "dew      = div(dew)\n",
    "\n",
    "DMC      = div(DMC)\n",
    "DSR      = div(DSR)\n",
    "ISI      = div(ISI)\n",
    "DC       = div(DC)\n",
    "WIND     = div(WIND)\n",
    "RH       = div(RH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dbfbd3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Var_data = xr.concat([pre,eva,leafhigh,skin,soiltem,rad,DMC,DSR,WIND,tem], dim = 'nueva_dimension')\n",
    "Var_data = Var_data.transpose('strftime','latitude','longitude','nueva_dimension')\n",
    "\n",
    "contar = int(len(Var_data)*0.8)\n",
    "train_data = Var_data[:contar,:,:,:]\n",
    "test_data  = Var_data[contar:,:,:,:]\n",
    "\n",
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "for kk in np.arange(0,len(train_data),1):\n",
    "    x_train.append(train_data[kk:kk+1,:,:,:-1].values) # tiempo,lat, lon, numero var\n",
    "    y_train.append(train_data[kk:kk+1,:,:,9].values)  \n",
    "\n",
    "x_train, y_train = np.array(x_train), np.array(y_train)\n",
    "x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1],x_train.shape[2],x_train.shape[3], x_train.shape[4]))\n",
    "y_train = np.reshape(y_train, (y_train.shape[0], y_train.shape[1] * y_train.shape[2] * y_train.shape[3]))\n",
    "\n",
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "for kk in np.arange(0,len(test_data),1):\n",
    "    x_test.append(test_data[kk:kk+1,:,:,:-1].values) # tiempo,lat, lon, numero var\n",
    "    y_test.append(test_data[kk:kk+1,:,:,9].values)\n",
    "    \n",
    "x_test, y_test = np.array(x_test), np.array(y_test)\n",
    "x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1],x_test.shape[2],x_test.shape[3], x_test.shape[4]))\n",
    "y_test = np.reshape(y_test, (y_test.shape[0], y_test.shape[1] * y_test.shape[2] * y_test.shape[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a2ad57d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv3d (Conv3D)             (None, 1, 5, 5, 64)       6976      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 1, 5, 5, 64)      256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv3d_1 (Conv3D)           (None, 1, 3, 3, 128)      73856     \n",
      "                                                                 \n",
      " conv_lstm2d (ConvLSTM2D)    (None, 1, 1, 128)         1180160   \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 98)                12642     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 49)                4851      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,278,741\n",
      "Trainable params: 1,278,613\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv3D(filters = 64, kernel_size = (1,3,3)\n",
    "                 input_shape=np.shape(x_train)[1:])) \n",
    "\n",
    "model.add(BatchNormalization()) \n",
    "model.add(Conv3D(filters = 128,kernel_size = (1,3,3)))\n",
    "model.add(tf.keras.layers.ConvLSTM2D(filters = 128, kernel_size = (3,3)))\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(49*2, activation='relu'))\n",
    "Dropout(0.6)\n",
    "model.add(Dense(np.shape(y_train)[1], activation='relu'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd8b2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam', loss='mse')\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "early_stop = EarlyStopping(monitor = 'val_loss', patience = 20, restore_best_weights = True)\n",
    "historia = model.fit(x_train, y_train,epochs = 100,verbose = 1, validation_data = (x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "947e3a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save(path + 'MODELOS3D/MODEL_C2.h5')\n",
    "#model.save_weights(path + 'MODELOS3D/PESOS_MODEL_C2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dab2224e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "prediccion = model.predict(x_test)\n",
    "prediccion = np.reshape(prediccion, (prediccion.shape[0], 7, 7)); prediccion = (prediccion * (max_tem - min_tem)) + min_tem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "778f23aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "contar2 = int(len(tem)*0.8)\n",
    "test_data_tem = tem[contar2:len(tem),:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6263718c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#nc4(prediccion, 't2m_predC3')\n",
    "real = np.reshape(y_test, (y_test.shape[0], 7, 7)); real = (real * (max_tem - min_tem)) + min_tem\n",
    "#nc4(real, 't2m_realC')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
