{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44933b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import scipy.stats as st\n",
    "import fwi_aux as fwi_xxx\n",
    "from datetime import timedelta\n",
    "import joblib\n",
    "import pickle\n",
    "\n",
    "from keras.models import load_model\n",
    "from matplotlib import pylab as plt\n",
    "from keras.models import Sequential\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.layers.convolutional import Conv1D, MaxPooling1D\n",
    "from keras.layers import Dense,LSTM, BatchNormalization, Dropout, Bidirectional, Flatten, LeakyReLU, Conv3D, MaxPooling3D\n",
    "\n",
    "import locale\n",
    "locale.setlocale(locale.LC_TIME, '')\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "path = os.getcwd() + '/'\n",
    "path_out = 'RESULTADOS_MONTECARLO/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d91a924",
   "metadata": {},
   "outputs": [],
   "source": [
    "nc_org     = xr.open_dataset('../redes/AL/DATA_DAY/2m_temperature.nc')-273.15\n",
    "#nc_tem_no     = xr.open_dataset('DATA_DAY/t2m_mod.nc')-273.15\n",
    "nc_tem     = xr.open_dataset('../redes/AL/DATA_TEM_MOD/t2m_mod.nc')-273.15\n",
    "nc_rad     = xr.open_dataset('../redes/AL/DATA_DAY/surface_solar_radiation_downwars.nc')/3600\n",
    "nc_soiltem = xr.open_dataset('../redes/AL/DATA_DAY/soil_temperature_level_1.nc')-273.15\n",
    "nc_pre     = xr.open_dataset('../redes/AL/DATA_DAY/total_precipitation.nc')*1000\n",
    "nc_dew     = xr.open_dataset('../redes/AL/DATA_DAY/2m_dewpoint_temperature.nc')-273.15\n",
    "nc_uwind   = xr.open_dataset('../redes/AL/DATA_DAY/10m_u_component_of_wind.nc')\n",
    "nc_vwind   = xr.open_dataset('../redes/AL/DATA_DAY/10m_v_component_of_wind.nc')\n",
    "nc_leafhigh= xr.open_dataset('../redes/AL/DATA_DAY/leaf_area_index_high_vegetation.nc')\n",
    "nc_leaflow = xr.open_dataset('../redes/AL/DATA_DAY/leaf_area_index_low_vegetation.nc')\n",
    "nc_skin    = xr.open_dataset('../redes/AL/DATA_DAY/skin_reservoir_content.nc')\n",
    "nc_vol     = xr.open_dataset('../redes/AL/DATA_DAY/volumetric_soil_water_layer_1.nc')\n",
    "nc_eva     = xr.open_dataset('../redes/AL/DATA_DAY/evaporation.nc')*(-1000)\n",
    "\n",
    "\n",
    "nc_BUI  = xr.open_dataset('../FWI/RESULTADOS_FWI10_NC/BUI.nc')\n",
    "nc_DC   = xr.open_dataset('../FWI/RESULTADOS_FWI10_NC/DC.nc')\n",
    "nc_DMC  = xr.open_dataset('../FWI/RESULTADOS_FWI10_NC//DMC.nc')\n",
    "nc_DSR  = xr.open_dataset('../FWI/RESULTADOS_FWI10_NC/DSR.nc')\n",
    "nc_FFMC = xr.open_dataset('../FWI/RESULTADOS_FWI10_NC/FFMC.nc')\n",
    "nc_FWI  = xr.open_dataset('../FWI/RESULTADOS_FWI10_NC/FWI.nc')\n",
    "nc_ISI  = xr.open_dataset('../FWI/RESULTADOS_FWI10_NC/ISI.nc')\n",
    "nc_M    = xr.open_dataset('../FWI/RESULTADOS_FWI10_NC/M.nc')\n",
    "nc_WIND = xr.open_dataset('../FWI/RESULTADOS_FWI10_NC/WIND.nc')\n",
    "\n",
    "nc_org = nc_org.rename({'t2m': 't2m_org'})\n",
    "\n",
    "tem      = nc_tem.t2m.assign_coords(strftime = nc_tem.t2m.strftime.values.astype('datetime64[ns]'))  #DESACTIVAR con datos modificados en tiempo o long\n",
    "pre      = nc_pre.tp.assign_coords(strftime = nc_pre.tp.strftime.values.astype('datetime64[ns]'))\n",
    "rad      = nc_rad.ssrd.assign_coords(strftime = nc_rad.ssrd.strftime.values.astype('datetime64[ns]'))\n",
    "soiltem  = nc_soiltem.stl1.assign_coords(strftime = nc_soiltem.stl1.strftime.values.astype('datetime64[ns]'))     \n",
    "dew      = nc_dew.d2m.assign_coords(strftime = nc_dew.d2m.strftime.values.astype('datetime64[ns]'))    \n",
    "uwind    = nc_uwind.u10.assign_coords(strftime = nc_uwind.u10.strftime.values.astype('datetime64[ns]'))   \n",
    "vwind    = nc_vwind.v10.assign_coords(strftime = nc_vwind.v10.strftime.values.astype('datetime64[ns]'))  \n",
    "leafhigh = nc_leafhigh.lai_hv.assign_coords(strftime = nc_leafhigh.lai_hv.strftime.values.astype('datetime64[ns]'))\n",
    "leaflow  = nc_leaflow.lai_lv.assign_coords(strftime = nc_leaflow.lai_lv.strftime.values.astype('datetime64[ns]'))\n",
    "skin     = nc_skin.src.assign_coords(strftime = nc_skin.src.strftime.values.astype('datetime64[ns]'))\n",
    "vol      = nc_vol.swvl1.assign_coords(strftime = nc_vol.swvl1.strftime.values.astype('datetime64[ns]'))\n",
    "eva      = nc_eva.e.assign_coords(strftime = nc_eva.e.strftime.values.astype('datetime64[ns]'))\n",
    "\n",
    "nc_BUI  = nc_BUI.BUI.rename({'time':'strftime'}) \n",
    "nc_DC   = nc_DC.DC.rename({'time':'strftime'}) \n",
    "nc_DMC  = nc_DMC.DCM.rename({'time':'strftime'})\n",
    "nc_DSR  = nc_DSR.DSR.rename({'time':'strftime'})\n",
    "nc_FFMC = nc_FFMC.FFMC.rename({'time':'strftime'})\n",
    "nc_FWI  = nc_FWI.FWI.rename({'time':'strftime'})\n",
    "nc_ISI  = nc_ISI.ISI.rename({'time':'strftime'})\n",
    "nc_M    = nc_M.M.rename({'time':'strftime'})\n",
    "nc_WIND = nc_WIND.WIND.rename({'time':'strftime'})\n",
    "\n",
    "BUI  = nc_BUI.assign_coords(strftime = nc_BUI.strftime.values.astype('datetime64[ns]'))  \n",
    "DC   = nc_DC.assign_coords(strftime = nc_DC.strftime.values.astype('datetime64[ns]'))  \n",
    "DMC  = nc_DMC.assign_coords(strftime = nc_DMC.strftime.values.astype('datetime64[ns]'))  \n",
    "DSR  = nc_DSR.assign_coords(strftime = nc_DSR.strftime.values.astype('datetime64[ns]'))  \n",
    "FFMC = nc_FFMC.assign_coords(strftime = nc_FFMC.strftime.values.astype('datetime64[ns]')) \n",
    "FWI  = nc_FWI.assign_coords(strftime = nc_FWI.strftime.values.astype('datetime64[ns]')) \n",
    "ISI  = nc_ISI.assign_coords(strftime = nc_ISI.strftime.values.astype('datetime64[ns]'))  \n",
    "M    = nc_M.assign_coords(strftime = nc_M.strftime.values.astype('datetime64[ns]')) \n",
    "WIND = nc_WIND.assign_coords(strftime = nc_WIND.strftime.values.astype('datetime64[ns]'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fbf813f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load(\"../Redes/AL/random_forest.joblib\")   #correr con venv sml\n",
    "#with open(\"../Redes/AL/random_forest_model.pkl\", \"rb\") as file:\n",
    "#    model = pickle.load(file)\n",
    "#model = pickle.load(\"../Redes/AL/random_forest.pkl\")   #correr con venv sml\n",
    "\n",
    "\n",
    "#rf_load = loaded_rf.predict(x_test)\n",
    "\n",
    "inicio_conteo = len(nc_tem.t2m[:int(len(nc_tem.t2m)*0.8)]) \n",
    "test_data_tem = nc_tem.t2m[inicio_conteo:,:,:].copy()\n",
    "#test_data_tem = test_data_tem.rename({'time':'strftime'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d4691a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_tem = nc_tem.t2m[inicio_conteo:,:,:].copy()\n",
    "\n",
    "def nc4(datos_datos, name):\n",
    "\n",
    "    from datetime import datetime, timedelta\n",
    "    from netCDF4 import Dataset,num2date,date2num\n",
    "        \n",
    "    a = test_data_tem.strftime[0].values\n",
    "    b = test_data_tem.strftime[len(test_data_tem.strftime)-1].values\n",
    "\n",
    "    nyears = len(test_data_tem.strftime);\n",
    "    unout = 'days since ' + str(pd.to_datetime(a).year) + '-' + str(pd.to_datetime(a).month) + '-' + str(pd.to_datetime(a).day)\n",
    "\n",
    "    nx, ny = (len(test_data_tem.latitude), len(test_data_tem.longitude))\n",
    "\n",
    "    lat = test_data_tem.latitude.values\n",
    "    lon = test_data_tem.longitude.values\n",
    "\n",
    "    dataout = datos_datos\n",
    "        \n",
    "    datesout = np.arange(datetime(int(pd.to_datetime(a).year),int(pd.to_datetime(a).month),int(pd.to_datetime(a).day)),\n",
    "                        datetime(int((pd.to_datetime(b) + timedelta(days=1)).year),int((pd.to_datetime(b) + timedelta(days=1)).month),int((pd.to_datetime(b) + timedelta(days=1)).day)),\n",
    "                        timedelta(days = 1)).astype(datetime)\n",
    "        \n",
    "    ncout = Dataset(path + path_out + name + '.nc','w','NETCDF3')\n",
    "    ncout.createDimension('longitude',ny)\n",
    "    ncout.createDimension('latitude',nx)\n",
    "    ncout.createDimension('time',nyears)\n",
    "    lonvar = ncout.createVariable('longitude','float32',('longitude'));lonvar[:] = lon\n",
    "    latvar = ncout.createVariable('latitude','float32',('latitude'));latvar[:] = lat\n",
    "    timevar = ncout.createVariable('time','float64',('time'));timevar.setncattr('units',unout);timevar[:]=date2num(datesout,unout)\n",
    "    myvar = ncout.createVariable(name,'float32',('time','latitude','longitude'));myvar.setncattr('units','');myvar[:] = dataout\n",
    "    ncout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c80f0369",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generador_ramdom2(name_distribution,nc, latitude, longitude,i):\n",
    "    \n",
    "    distribution = getattr(st, name_distribution)  \n",
    "    diff         = nc[:,latitude,longitude].median() - nc[i,latitude,longitude].values  \n",
    "    params       = distribution.fit(nc[:,latitude,longitude] - diff.to_numpy())        \n",
    "    arg          = params[:-2]\n",
    "    scale        = params[-1]\n",
    "    loc          = params[-2]\n",
    "    random       = distribution.rvs(size = num_monte, loc=loc, scale=scale, *arg)\n",
    "    random[random > nc[:,latitude,longitude].max().values] = nc[:,latitude,longitude].max().values\n",
    "    random[random < nc[:,latitude,longitude].min().values] = nc[:,latitude,longitude].min().values\n",
    "    \n",
    "    return(random)\n",
    "\n",
    "def resultados_prob (prediccion, categoria, num_monte):      \n",
    "    lista_names= []\n",
    "    matriz_prob = np.zeros((1, len(T2.longitude) * len(T2.latitude)))\n",
    "    suma = 0\n",
    "    \n",
    "    for latitude in np.arange(0,len(T2.latitude),1):\n",
    "        for longitude in np.arange(0,len(T2.longitude),1):\n",
    "            probabilidad        = (np.count_nonzero(prediccion[:,latitude, longitude] == categoria)/num_monte)*100\n",
    "            matriz_prob[:,suma] = probabilidad; suma += 1\n",
    "            lista_names         = np.append(lista_names, str(latitude) + ',' + str(longitude))\n",
    "            \n",
    "    df_prob        = pd.DataFrame(matriz_prob,columns = lista_names)  \n",
    "    resultado_prob = df_prob.values.reshape(1,len(T2.latitude), len(T2.longitude))  \n",
    "    return np.round(resultado_prob,1)\n",
    "\n",
    "\n",
    "def data_model(matriz_var_random, lista_names, num_monte, T2):\n",
    "    \n",
    "    df_var_random     = pd.DataFrame(matriz_var_random,columns = lista_names)\n",
    "    result_var_random = df_var_random.values.reshape(num_monte,len(T2.latitude), len(T2.longitude))\n",
    "    dim_var_random    = np.reshape(result_var_random, (result_var_random.shape[0], result_var_random.shape[1],result_var_random.shape[2],1))\n",
    "    return dim_var_random\n",
    "\n",
    "def threshold(data,percentil): \n",
    "    matriz_thrs = np.zeros((1, len(T2.longitude) * len(T2.latitude)))\n",
    "    suma_thrs   = 0\n",
    "    lista_names_thrs = []\n",
    "\n",
    "    for latitude in np.arange(0,len(data.latitude),1):\n",
    "\n",
    "        for longitude in np.arange(0,len(data.longitude),1):\n",
    "\n",
    "            data_pixel = data[:,latitude,longitude].copy()\n",
    "            thrs       = np.round(np.percentile(data_pixel,percentil),4)\n",
    "\n",
    "            matriz_thrs[:,suma_thrs] = thrs ; suma_thrs += 1\n",
    "            lista_names_thrs         = np.append(lista_names_thrs, str(latitude) + ',' + str(longitude))\n",
    "\n",
    "    df_thrs = pd.DataFrame(matriz_thrs,columns = lista_names_thrs)\n",
    "    resultado_thrs  = df_thrs.values.reshape(1,len(data.latitude), len(data.longitude))\n",
    "    \n",
    "    \n",
    "    return resultado_thrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d54893c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_monte = 100 # numero de iteraciones en el mismo dia\n",
    "T2 = nc_org.t2m_org\n",
    "\n",
    "thrs_alta  = 29.5\n",
    "thrs_media = 24.71\n",
    "clases_reales2 = nc_tem.t2m[:,:,:].values.copy()\n",
    "clases_reales2[clases_reales2 < thrs_alta]  = 0 \n",
    "clases_reales2[clases_reales2 >= thrs_media] = 3 #6\n",
    "\n",
    "\n",
    "for ciclo in np.arange(inicio_conteo,len(nc_pre.tp),1): \n",
    "\n",
    "    print(ciclo)\n",
    "    fin         = ciclo\n",
    "    ini         = ciclo - 10\n",
    "    suma        = 0\n",
    "    lista_names = []\n",
    "    \n",
    "    matriz_prediccion     = np.zeros((num_monte, len(T2.longitude) * len(T2.latitude)))\n",
    " \n",
    "\n",
    "    for latitude in np.arange(0,len(T2.latitude),1):\n",
    "        for longitude in np.arange(0,len(T2.longitude),1):\n",
    "        \n",
    "            eva_random_1     = generador_ramdom2('burr', nc_eva.e, latitude, longitude, fin)\n",
    "            v10_random_1     = generador_ramdom2('norm', nc_vwind.v10, latitude, longitude, fin)\n",
    "            tp_random_1      = generador_ramdom2('expon', nc_pre.tp, latitude, longitude, fin) #genpareto, lognorm\n",
    "            lai_hv_random_1  = generador_ramdom2('norm', nc_leafhigh.lai_hv, latitude, longitude, fin)\n",
    "            src_random_1     = generador_ramdom2('norm', nc_skin.src, latitude, longitude, fin)\n",
    "            ssrd_random_1    = generador_ramdom2('burr', nc_rad.ssrd, latitude, longitude, fin)\n",
    "            t2m_org_random_1 = generador_ramdom2('burr', nc_org.t2m_org, latitude, longitude, fin)\n",
    "            u10_random_1     = generador_ramdom2('norm', nc_uwind.u10, latitude, longitude, fin)\n",
    "            d2m_random_1     = generador_ramdom2('burr', nc_dew.d2m, latitude, longitude, fin)  \n",
    "            stl1_random_1    = generador_ramdom2('norm', nc_soiltem.stl1, latitude, longitude, fin)\n",
    "            \n",
    "            eva_random_1[eva_random_1 > nc_eva.e.max().values]                 = nc_eva.e.max() \n",
    "            v10_random_1[v10_random_1 > nc_vwind.v10.max().values]             = nc_vwind.v10.max()  \n",
    "            tp_random_1[tp_random_1 > nc_pre.tp.max().values]                  = nc_pre.tp.max()  \n",
    "            lai_hv_random_1[lai_hv_random_1 > nc_leafhigh.lai_hv.max().values] = nc_leafhigh.lai_hv.max()  \n",
    "            src_random_1[src_random_1 > nc_skin.src.max().values]              = nc_skin.src.max()  \n",
    "            ssrd_random_1[ssrd_random_1 > nc_rad.ssrd.max().values]            = nc_rad.ssrd.max()\n",
    "            t2m_org_random_1[t2m_org_random_1 > nc_org.t2m_org.max().values]   = nc_org.t2m_org.max()\n",
    "            u10_random_1[u10_random_1 > nc_uwind.u10.max().values]             = nc_uwind.u10.max()                  \n",
    "            d2m_random_1[d2m_random_1 > nc_dew.d2m.max().values]               = nc_dew.d2m.max()\n",
    "            stl1_random_1[stl1_random_1 > nc_soiltem.stl1.max().values]        = nc_soiltem.stl1.max()\n",
    "\n",
    "            eva_random_1[eva_random_1 < nc_eva.e.min().values]                 = nc_eva.e.min()\n",
    "            v10_random_1[v10_random_1 < nc_vwind.v10.min().values]             = nc_vwind.v10.min()\n",
    "            tp_random_1[tp_random_1 < nc_pre.tp.min().values]                  = nc_pre.tp.min()\n",
    "            lai_hv_random_1[lai_hv_random_1 < nc_leafhigh.lai_hv.min().values] = nc_leafhigh.lai_hv.min()\n",
    "            src_random_1[src_random_1 < nc_skin.src.min().values]              = nc_skin.src.min()\n",
    "            ssrd_random_1[ssrd_random_1 < nc_rad.ssrd.min().values]            = nc_rad.ssrd.min()\n",
    "            t2m_org_random_1[t2m_org_random_1 < nc_org.t2m_org.min().values]   = nc_org.t2m_org.min()\n",
    "            u10_random_1[u10_random_1 < nc_uwind.u10.min().values]             = nc_uwind.u10.min()\n",
    "            d2m_random_1[d2m_random_1 < nc_dew.d2m.min().values]               = nc_dew.d2m.min()\n",
    "            stl1_random_1[stl1_random_1 < nc_soiltem.stl1.min().values]        = nc_soiltem.stl1.min()\n",
    "            \n",
    " \n",
    "            mylist_DCM = []\n",
    "            mylist_DSR = []\n",
    "            mylist_WIND = []\n",
    "             \n",
    "            for ii in np.arange(0, num_monte, 1):  #Indices FWI\n",
    "\n",
    "                d2m_fwi     = nc_dew.d2m[ini:fin+1,latitude,longitude].to_dataframe().drop(['longitude', 'latitude'], axis=1)  \n",
    "                t2m_org_fwi = nc_org.t2m_org[ini:fin+1,latitude,longitude].to_dataframe().drop(['longitude', 'latitude'], axis=1)\n",
    "                v10_fwi     = nc_vwind.v10[ini:fin+1,latitude,longitude].to_dataframe().drop(['longitude', 'latitude'], axis=1)\n",
    "                u10_fwi     = nc_uwind.u10[ini:fin+1,latitude,longitude].to_dataframe().drop(['longitude', 'latitude'], axis=1)\n",
    "                tp_fwi      = nc_pre.tp[ini:fin+1,latitude,longitude].to_dataframe().drop(['longitude', 'latitude'], axis=1)\n",
    "            \n",
    "                dataframe_unido = pd.DataFrame([])\n",
    "                lista_nc        = [d2m_fwi, t2m_org_fwi, v10_fwi, u10_fwi, tp_fwi]\n",
    "                \n",
    "                for i in np.arange(0,len(lista_nc),1):\n",
    "                    array_org       = lista_nc[i][list(lista_nc[i].keys())[0]].values\n",
    "                    dataframe_unico = pd.DataFrame(array_org, columns = list(lista_nc[i].keys()))\n",
    "                    dataframe_unido = pd.concat([dataframe_unido,dataframe_unico],axis = 1)\n",
    "                    \n",
    "                fechas                    = pd.DataFrame(nc_pre.tp[ini:fin+1,latitude,longitude].strftime.values, columns = ['Fecha'])\n",
    "                dataframe_unido           = pd.concat([fechas,dataframe_unido],axis = 1)\n",
    "                dataframe_unido           = dataframe_unido.set_index('Fecha')\n",
    "                fechas                    = pd.DataFrame(dataframe_unido.index, columns = ['Fecha'])\n",
    "                dataframe_unido.index     = pd.to_datetime(dataframe_unido.index)\n",
    "                dataframe_unido.iloc[-1:] = [d2m_random_1[ii],t2m_org_random_1[ii],v10_random_1[ii], u10_random_1[ii], tp_random_1[ii]]\n",
    "\n",
    "                dataframe_unido['rh']   = 100*(np.exp((17.625*dataframe_unido['d2m'])/(243.04+dataframe_unido['d2m']))/np.exp((17.625*dataframe_unido['t2m_org'])/(243.04+dataframe_unido['t2m_org'])))\n",
    "                dataframe_unido['WIND'] = np.sqrt(dataframe_unido['u10']**2 + dataframe_unido['v10']**2) * 3.6\n",
    "\n",
    "                dataframe_unido['MES'] = dataframe_unido.index.strftime('%m')\n",
    "                dataframe_unido        = dataframe_unido.reset_index()[['MES','t2m_org','rh', 'WIND', 'tp']].rename({'t2m_org':'TEMP','rh':'RH', 'tp':'RAIN'}, axis = 1)\n",
    "                \n",
    "                data_csv = fwi_xxx.xxx(dataframe_unido)\n",
    "                data_csv = data_csv.iloc[10]\n",
    "                \n",
    "                mylist_DCM.append(data_csv['DCM']) \n",
    "                mylist_DSR.append(data_csv['DSR'])\n",
    "                mylist_WIND.append(data_csv['WIND'])\n",
    "                    \n",
    "            DCM_random_1 = np.array(mylist_DCM)   \n",
    "            DSR_random_1 = np.array(mylist_DSR)\n",
    "            WIND_random_1 = np.array(mylist_WIND)\n",
    "            \n",
    "            DCM_random_1[DCM_random_1    > DCM_random_1.max()]  = DCM_random_1.max()\n",
    "            DSR_random_1[DSR_random_1    > DSR_random_1.max()]  = DSR_random_1.max()\n",
    "            WIND_random_1[WIND_random_1  > WIND_random_1.max()] = WIND_random_1.max()\n",
    "            \n",
    "            \n",
    "            DCM_random_1[DCM_random_1    < DCM_random_1.min()]  = DCM_random_1.min()\n",
    "            DSR_random_1[DSR_random_1    < DSR_random_1.min()]  = DSR_random_1.min()\n",
    "            WIND_random_1[WIND_random_1  < WIND_random_1.min()] = WIND_random_1.min()\n",
    "            \n",
    "            x_test = np.stack((tp_random_1,eva_random_1,ssrd_random_1,stl1_random_1,lai_hv_random_1,src_random_1,DCM_random_1,DSR_random_1,WIND_random_1),axis = 1)\n",
    "            x_test = pd.DataFrame(x_test, columns=['tp', 'e', 'ssrd','stl1','lai_hv','src','DCM','DSR','WIND'])\n",
    "            prediccion_dia = model.predict(x_test)\n",
    "            \n",
    "            matriz_prediccion[:,suma]    = prediccion_dia;   suma += 1\n",
    "            lista_names    = np.append(lista_names, str(latitude) + ',' + str(longitude))\n",
    "            \n",
    "            \n",
    "    df_prediccion  = pd.DataFrame(matriz_prediccion,columns = lista_names).copy()\n",
    "    prediccion = df_prediccion.values.reshape(100,7,7).copy()\n",
    "                        \n",
    "    prediccion[prediccion < thrs_media]  = 0    \n",
    "    prediccion[prediccion >= thrs_alta]  = 4  \n",
    "    prediccion[prediccion > thrs_media]  = 2 \n",
    "    \n",
    "    probabilidad_0 = resultados_prob(prediccion, 0, num_monte) # prediccion, categoria, num_monte\n",
    "    probabilidad_2 = resultados_prob(prediccion, 2, num_monte)\n",
    "    probabilidad_4 = resultados_prob(prediccion, 4, num_monte)  \n",
    "    \n",
    "    if ciclo == inicio_conteo:\n",
    "        resultado_final_0 = probabilidad_0.copy()\n",
    "        resultado_final_2 = probabilidad_2.copy()\n",
    "        resultado_final_4 = probabilidad_4.copy()    \n",
    "        \n",
    "    else:\n",
    "        resultado_final_0 = np.concatenate((resultado_final_0, probabilidad_0), axis=0) \n",
    "        resultado_final_2 = np.concatenate((resultado_final_2, probabilidad_2), axis=0)\n",
    "        resultado_final_4 = np.concatenate((resultado_final_4, probabilidad_4), axis=0)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3435b957",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nc4(resultado_final_0, 'class_RF_0')\n",
    "#nc4(resultado_final_2, 'class_RF_2')\n",
    "#nc4(resultado_final_4, 'class_RF_4')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
